{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitterscrapping.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExvTh_wGaj6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tweepy\n",
        "import csv\n",
        "import pandas as pd\n",
        "consumer_key= ''\n",
        "consumer_secret= ''\n",
        "access_token= ''\n",
        "access_token_secret= ''\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth,wait_on_rate_limit=True)\n",
        "csvFile = open('tweets.csv', 'a')\n",
        "csvWriter = csv.writer(csvFile)\n",
        "for tweet in tweepy.Cursor(api.search,q=\"#blacklivesmatter\",count=50000,lang=\"en\",since=\"2017-04-03\").items(50000):\n",
        "    print (tweet.created_at, tweet.text)\n",
        "    csvWriter.writerow([tweet.created_at, tweet.text.encode('utf-8')])\n",
        "# Get your twitter developer account get a website then create app on twitter developer account \n",
        "# and you will have all 4(consumer_key= '',consumer_secret= '',access_token= '',access_token_secret= ''\n",
        "# of your own and will able to run the code to scrape the tweets in tweets.csv as i did.  Enjoy the data....as now onwards data is money....."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}